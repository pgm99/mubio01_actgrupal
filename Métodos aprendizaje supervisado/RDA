```{r}
# División en datos de entrenamiento y prueba (70%-30%)
set.seed(100)
index <- createDataPartition(expression$class, p = 0.7, list = FALSE)
train_data <- expression[index, ]
test_data <- expression[-index, ]

# Eliminar variables constantes antes de entrenar
train_data <- train_data %>% select_if(~ !is.factor(.) && var(.) > 0)

# Asegurar que `test_data` solo tenga las mismas columnas que `train_data`
test_data <- test_data %>% select(all_of(colnames(train_data)))

# Verificar que `class` sigue presente en los datos
train_data$class <- expression$class[index]
test_data$class <- expression$class[-index]

# Convertir `train_data` y `test_data` en `data.frame()` con `class` como factor
train_data <- as.data.frame(train_data)
test_data <- as.data.frame(test_data)
train_data$class <- as.factor(train_data$class)
test_data$class <- as.factor(test_data$class)

# Asegurar que los nombres de columnas sean válidos y coincidan en ambos conjuntos
colnames(train_data) <- make.names(colnames(train_data), unique = TRUE)
colnames(test_data) <- make.names(colnames(test_data), unique = TRUE)

# Verificar si hay diferencias en los nombres de las columnas
column_differences <- setdiff(colnames(train_data), colnames(test_data))
if (length(column_differences) > 0) {
  print("Diferencias en columnas entre train_data y test_data después de limpiar nombres:")
  print(column_differences)
}

# Entrenar el modelo RDA
rda_model <- rda(class ~ ., data = train_data, gamma = 0.1, lambda = 0.5)

# Hacer predicciones en los datos de prueba
rda_predictions <- predict(rda_model, newdata = test_data)$class

# Evaluar el modelo con matriz de confusión y métricas
rda_conf_matrix <- confusionMatrix(rda_predictions, test_data$class)
print(rda_conf_matrix)

# Extraer métricas de evaluación
results <- data.frame(Model = "RDA",
                      Accuracy = rda_conf_matrix$overall["Accuracy"],
                      Kappa = rda_conf_matrix$overall["Kappa"],
                      F1_Score = rda_conf_matrix$byClass["F1"])

# Mostrar los resultados finales
print(results)

```
Se ha seleccionado Regularized Discriminant Analysis (RDA) como modelo de clasificación debido a su capacidad para manejar datos con muchas variables y alta colinealidad, como ocurre en la expresión genética. RDA combina lo mejor de los enfoques lineales y cuadráticos, ajustando la regularización para mejorar la estabilidad y precisión en la clasificación.

A diferencia de otros métodos, RDA permite adaptar la matriz de covarianza mediante dos parámetros (gamma y lambda), lo que evita problemas de sobreajuste y mejora la capacidad del modelo para distinguir entre clases cuando los datos son complejos.

El modelo ha mostrado una precisión del 92.44% y una alta concordancia entre predicciones y valores reales (Kappa = 0.9014). Aunque el rendimiento es sólido en la mayoría de las clases, se ha observado que la categoría HPB presenta más errores de clasificación, lo que podría mejorarse con ajustes en los hiperparámetros o técnicas de balanceo.

En general, RDA ha sido elegido por su capacidad para ofrecer un equilibrio entre modelos simples y flexibles, logrando buenos resultados en este conjunto de datos.
